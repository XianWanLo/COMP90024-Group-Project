{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11758843,"sourceType":"datasetVersion","datasetId":7381856},{"sourceId":11836603,"sourceType":"datasetVersion","datasetId":7436486},{"sourceId":11836688,"sourceType":"datasetVersion","datasetId":7436548},{"sourceId":11841256,"sourceType":"datasetVersion","datasetId":7439786},{"sourceId":399332,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":326844,"modelId":347742},{"sourceId":399417,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":326894,"modelId":347790},{"sourceId":399503,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":326962,"modelId":347860}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport time\n\nclass DynamicEvidenceDataset(Dataset):\n    def __init__(self, eval_path, claim_path, evidence_path, tokenizer, max_len=512):\n        self.eval_data = self.load_data(eval_path)\n        self.claim_data = self.load_data(claim_path)\n        self.evidence_data = self.load_data(evidence_path)\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.label_map = {'SUPPORTS': 0, 'REFUTES': 1, 'NOT_ENOUGH_INFO': 2, 'DISPUTED': 3}\n\n    def load_data(self, path):\n        with open(path, 'r') as f:\n            return json.load(f)\n\n    def __len__(self):\n        return len(self.claim_data)\n\n    def __getitem__(self, idx):\n        claim_id = list(self.eval_data.keys())[idx]\n        evidences = self.eval_data.get(claim_id, {}).get('evidences', [])\n\n        # Fetch claim text\n        claim_text = self.claim_data[claim_id]['claim_text']\n\n        # Fetch evidence texts\n        evidence_texts = [self.evidence_data.get(e_id, \"\") for e_id in evidences]\n        evidence = \" [SEP] \".join(evidence_texts)\n\n        # Construct input text\n        inputs = self.tokenizer(\"CLAIM: \" + claim_text + \" [SEP] EVIDENCE: \" + evidence,\n                                truncation=True, padding='max_length',\n                                max_length=self.max_len, return_tensors='pt')\n\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n        inputs['labels'] = self.label_map[self.claim_data[claim_id]['claim_label']]  \n        return inputs\n\n\ndef create_dataloader(eval_path, claim_path, evidence_path, tokenizer, batch_size=16, max_len=512):\n    dataset = DynamicEvidenceDataset(eval_path, claim_path, evidence_path, tokenizer, max_len)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    return dataloader\n\n\ndef evaluate_model(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    start_time = time.time()\n\n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to('cuda')\n            attention_mask = batch['attention_mask'].to('cuda')\n            labels = batch['labels'].to('cuda')\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            _, preds = torch.max(logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    end_time = time.time()\n    inference_time = end_time - start_time\n\n    return all_preds, all_labels, inference_time\n\n\ndef run_evaluation(eval_path, claim_path, evidence_path, model, tokenizer,output_path, batch_size=16, max_len=512):\n    \n    label_map = {0: 'SUPPORTS', 1: 'REFUTES', 2: 'NOT_ENOUGH_INFO', 3: 'DISPUTED'}\n    \n    dataloader = create_dataloader(eval_path, claim_path, evidence_path, tokenizer, batch_size, max_len)\n    preds, labels, inference_time = evaluate_model(model, dataloader)\n\n    # Calculate metrics\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average='weighted')\n    recall = recall_score(labels, preds, average='weighted')\n    f1 = f1_score(labels, preds, average='weighted')\n    accuracy = accuracy_score(labels, preds)\n    \n    # Prepare output dictionary (key: claim_id)\n    output_data = {}\n    eval_data = json.load(open(eval_path))\n\n    for idx, claim_id in enumerate(eval_data.keys()):\n        output_data[claim_id] = {\n            \"evidences\": eval_data[claim_id][\"evidences\"],\n            \"claim_label\": label_map[int(preds[idx])]\n        }\n\n    with open(output_path, 'w') as f:\n        json.dump(output_data, f, indent=4)\n\n    print(f\"Predictions saved to {output_path}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"Total Inference Time: {inference_time:.2f} seconds\")\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:54:22.047942Z","iopub.execute_input":"2025-05-17T23:54:22.048186Z","iopub.status.idle":"2025-05-17T23:54:27.261421Z","shell.execute_reply.started":"2025-05-17T23:54:22.048168Z","shell.execute_reply":"2025-05-17T23:54:27.260542Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"BERT Model Evaluation","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\n\nstate_dict_path = \"/kaggle/input/bert-pretrained/pytorch/default/1/baseline_bert_model_Autocast_explicitMarker_LR5e05.pt\"\neval_path = \"/kaggle/input/evidence-prediction/MyPredictions\"\nclaim_path = \"/kaggle/input/dev-claims/dev-claims.json\"\nevidence_path = \"/kaggle/input/evidence/evidence.json\"\noutput_path = \"/kaggle/working/new_BERT_prediction.json\"\nbatch_size = 16\nmax_len = 512\n\ndef load_model_and_tokenizer(state_dict_path):\n    \"\"\" Load the pre-trained model and tokenizer from the directory. \"\"\"\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n    if state_dict_path:\n        state_dict = torch.load(state_dict_path)\n        model.load_state_dict(state_dict)\n        print(\"successfully loaded model\")\n    model.to('cuda')\n    return model, tokenizer\n\n\n# Load model and tokenizer\nmodel, tokenizer = load_model_and_tokenizer(state_dict_path)\n\n# Run evaluation\nrun_evaluation(eval_path, claim_path, evidence_path, model, tokenizer,output_path, batch_size, max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:54:27.262248Z","iopub.execute_input":"2025-05-17T23:54:27.262590Z","iopub.status.idle":"2025-05-17T23:55:04.895472Z","shell.execute_reply.started":"2025-05-17T23:54:27.262566Z","shell.execute_reply":"2025-05-17T23:55:04.894704Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 23:54:36.763739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747526076.982688      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747526077.045183      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98581cbfcab2422e99153c5d0d4e0ea6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ea7c5cab994cbda54ca0751f5def60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7753e15a6c50410ba64ec3937a63c1ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1120e585da7e40debf7c231e51b1c966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2711d6111c842c18e77bb1e68ece684"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"successfully loaded model\nPredictions saved to /kaggle/working/BERT_prediction.json\nAccuracy: 0.4610\nPrecision: 0.3464\nRecall: 0.4610\nF1 Score: 0.3806\nTotal Inference Time: 4.53 seconds\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"DeBERTa Model Evaluation","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nstate_dict_path = \"/kaggle/input/deberta-v3-pretrained/pytorch/default/1/deBERTa_v3_best_model.pt\"\neval_path = \"/kaggle/input/evidence-prediction/MyPredictions\"\nclaim_path = \"/kaggle/input/dev-claims/dev-claims.json\"\nevidence_path = \"/kaggle/input/evidence/evidence.json\"\noutput_path = \"/kaggle/working/deBERTa_prediction.json\"\nbatch_size = 4\nmax_len = 512\n\ndef load_model_and_tokenizer(state_dict_path):\n    \"\"\" Load the pre-trained model and tokenizer from the directory. \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n    model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=4)\n    if state_dict_path:\n        state_dict = torch.load(state_dict_path)\n        model.load_state_dict(state_dict)\n        print(\"successfully loaded model\")\n    model.to('cuda')\n    return model, tokenizer\n\n\n# Load model and tokenizer\nmodel, tokenizer = load_model_and_tokenizer(state_dict_path)\n\n# Run evaluation\nrun_evaluation(eval_path, claim_path, evidence_path, model, tokenizer,output_path, batch_size, max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:55:04.898008Z","iopub.execute_input":"2025-05-17T23:55:04.898492Z","iopub.status.idle":"2025-05-17T23:55:27.305198Z","shell.execute_reply.started":"2025-05-17T23:55:04.898472Z","shell.execute_reply":"2025-05-17T23:55:27.304309Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d9b39c4bba34889b3c93546bfa19e85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08351b1f65d494d902d93513d7c652e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a7bd2478ad405baa30c46d3b5ccc16"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49c4f6d48c71447a8835375f8124b3ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf564db0f2de47109cf0e2869b68ca40"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"successfully loaded model\nPredictions saved to /kaggle/working/deBERTa_prediction.json\nAccuracy: 0.4481\nPrecision: 0.3525\nRecall: 0.4481\nF1 Score: 0.3858\nTotal Inference Time: 7.43 seconds\n","output_type":"stream"}],"execution_count":3}]}