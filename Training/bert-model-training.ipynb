{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Util","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\nimport torch\nimport json\n\n# Custom Dataset\nclass ClaimClassificationDataset(Dataset):\n    def __init__(self, data_path, tokenizer, max_len=512):\n        self.data = self.load_data(data_path)\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.label_map = {'SUPPORTS': 0, 'REFUTES': 1, 'NOT_ENOUGH_INFO': 2, 'DISPUTED': 3}\n\n    def load_data(self, data_path):\n        \"\"\"Load and preprocess data from JSON.\"\"\"\n        with open(data_path, \"r\") as f:\n            data = json.load(f)\n        return data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        claim = \"CLAIM:\" + item['claim_text']\n        evidence = \" [SEP] EVIDENCE:\".join(item['evidences'])\n        #claim = item['claim_text']\n        #evidence = \" [SEP] \".join(item['evidences'])\n        inputs = self.tokenizer(claim + evidence,\n                                truncation=True, padding=\"max_length\",  # Use dynamic padding\n                                max_length=self.max_len, return_tensors='pt')\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n        inputs['labels'] = torch.tensor(self.label_map[item['claim_label']])\n        return inputs\n\ndef create_dataloaders(train_path, dev_path, tokenizer, batch_size=16, max_len=512):\n    \"\"\"\n    Creates training and validation data loaders.\n\n    Args:\n        train_path (str): Path to training data JSON file.\n        dev_path (str): Path to development data JSON file.\n        tokenizer (transformers.Tokenizer): BERT tokenizer.\n        batch_size (int): Batch size for data loaders.\n        max_len (int): Maximum length for tokenization.\n\n    Returns:\n        DataLoader: Training and validation data loaders.\n    \"\"\"\n    train_dataset = ClaimClassificationDataset(train_path, tokenizer, max_len)\n    dev_dataset = ClaimClassificationDataset(dev_path, tokenizer, max_len)\n\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, dev_loader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:01:53.036955Z","iopub.execute_input":"2025-05-17T10:01:53.037193Z","iopub.status.idle":"2025-05-17T10:02:33.049438Z","shell.execute_reply.started":"2025-05-17T10:01:53.037167Z","shell.execute_reply":"2025-05-17T10:02:33.048621Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 10:02:14.012199: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747476134.403356      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747476134.531077      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.amp import GradScaler, autocast\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# GradScaler\nscaler = GradScaler()  \n\n   \ndef train_one_epoch(model, train_loader, optimizer, scheduler, autocast_flag=False):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        # Move data to device\n        # print(batch[\"input_ids\"])\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        labels = batch[\"labels\"].to(DEVICE)\n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        if autocast_flag:\n            with autocast(device_type='cuda'):  # Updated autocast\n                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n        else:\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n             # Backward pass\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    return avg_loss\n\n\ndef evaluate(model, dev_loader):\n    model.eval()\n    total_loss = 0\n    correct_predictions = 0\n    total_samples = 0\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in dev_loader:\n            input_ids = batch[\"input_ids\"].to(DEVICE)\n            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n            labels = batch[\"labels\"].to(DEVICE)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_loss += loss.item()\n            # Compute accuracy\n            logits = outputs.logits\n            _, preds = torch.max(logits, dim=1)\n            correct_predictions += (preds == labels).sum().item()\n            total_samples += labels.size(0)\n\n            # Collect all predictions and labels for metrics calculation\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate average loss and accuracy\n    avg_loss = total_loss / len(dev_loader)\n    accuracy = correct_predictions / total_samples\n\n    # Calculate precision, recall, and F1 score\n    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n\n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    print(\"Confusion Matrix:\\n\", cm)\n    \n    # Classification report for per-class recall\n    # report = classification_report(all_labels, all_preds, zero_division=0)\n    # print(report)\n\n    # Return all metrics\n    metrics = {\n        \"avg_loss\": avg_loss,\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1\n    }\n\n    return metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}