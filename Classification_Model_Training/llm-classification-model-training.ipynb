{"cells":[{"cell_type":"markdown","metadata":{"id":"IF5hWkmHT3f5"},"source":["Zero-shot learning (Direct Prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-05-17T09:05:02.729171Z","iopub.status.busy":"2025-05-17T09:05:02.728878Z","iopub.status.idle":"2025-05-17T09:05:02.734690Z","shell.execute_reply":"2025-05-17T09:05:02.733894Z","shell.execute_reply.started":"2025-05-17T09:05:02.729150Z"},"id":"DHFfFSg_Rqgz","trusted":true},"outputs":[],"source":["# pip install accelerate\n","import time\n","import json\n","import torch\n","\n","\n","def zero_shot_direct_prompt_classification(claim_text, evidences, tokenizer, model, max_len=512 ):\n","\n","    prompt = (\n","        \"Classify if the evidences SUPPORTS, REFUTES, have NOT_ENOUGH_INFO or DISPUTED regarding the claim. Examples are provided for you to understand the logic.\\n\"\n","\n","        f\"Claim: {claim_text}\\n\"\n","        f\"Evidence: {' [SEP] '.join(evidences)}\\n\"\n","    )\n","\n","    # Tokenize and generate output\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_len).input_ids.to(\"cuda\")\n","    output_ids = model.generate(input_ids, max_length=10)\n","    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","    # Ensure the output is one of the valid labels\n","    valid_labels = [\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n","    output = output.strip().upper()\n","\n","    return output if output in valid_labels else \"NOT_ENOUGH_INFO\""]},{"cell_type":"markdown","metadata":{"id":"36ZoWme1RtLH"},"source":["Zero-shot learning (Role-play Prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-05-17T09:05:02.736067Z","iopub.status.busy":"2025-05-17T09:05:02.735807Z","iopub.status.idle":"2025-05-17T09:05:02.751604Z","shell.execute_reply":"2025-05-17T09:05:02.751004Z","shell.execute_reply.started":"2025-05-17T09:05:02.736047Z"},"id":"yOJhiKvXRrqy","trusted":true},"outputs":[],"source":["def zero_shot_roleplay_prompt_classification(claim_text, evidences, tokenizer, model, max_len=512):\n","\n","    prompt = (\n","        \"You are a fact-checking assistant and your task is to classify if the evidences SUPPORTS, REFUTES, have NOT_ENOUGH_INFO or DISPUTED regarding the claim.\\n\"\n","\n","        f\"Claim: {claim_text}\\n\"\n","        f\"Evidence: {' [SEP] '.join(evidences)}\\n\"\n","    )\n","\n","    # Tokenize and generate output\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\",truncation=True, max_length=max_len).input_ids.to(\"cuda\")\n","    output_ids = model.generate(input_ids, max_length=10)\n","    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","    # Ensure the output is one of the valid labels\n","    valid_labels = [\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n","    output = output.strip().upper()\n","\n","    return output if output in valid_labels else \"NOT_ENOUGH_INFO\""]},{"cell_type":"markdown","metadata":{"id":"9NryQj_EU_2K"},"source":["Few-shot Learning (Direct Prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-05-17T09:05:02.752514Z","iopub.status.busy":"2025-05-17T09:05:02.752305Z","iopub.status.idle":"2025-05-17T09:05:02.764442Z","shell.execute_reply":"2025-05-17T09:05:02.763723Z","shell.execute_reply.started":"2025-05-17T09:05:02.752492Z"},"id":"DJzR7q-qRsDP","trusted":true},"outputs":[],"source":["def few_shot_direct_prompt_classification(claim_text, evidences, tokenizer, model, max_len=512 ):\n","\n","    prompt = (\n","         \"Classify if the evidences SUPPORTS, REFUTES, have NOT_ENOUGH_INFO or DISPUTED regarding the claim. Examples are provided below for reference.\\n\"\n","\n","        \"Example 1:\\n\"\n","        \"Claim: \\\"Our harmless emissions of trifling quantities of carbon dioxide cannot possibly acidify the oceans.\\\"\\n\"\n","        \"Evidence: \\\"Carbon dioxide also causes ocean acidification because it dissolves in water to form carbonic acid.\\\", \"\n","        \"\\\"Marine calcifiers exhibit mixed responses to CO 2-induced ocean acidification.\\\"\\n\"\n","        \"Answer: REFUTES\\n\\n\"\n","\n","        \"Example 2:\\n\"\n","        \"Claim: \\\"Sea-level rise does not seem to depend on ocean temperature, and certainly not on CO2\\\"\\n\"\n","        \"Evidence: \\\"This depth depends on (among other things) temperature and the amount of CO 2 dissolved in the ocean.\\\", \"\n","        \"\\\"Because different climate models have slightly different patterns of ocean heating, they do not agree fully on the predictions for the contribution of ocean heating on sea level rise.\\\"\\n\"\n","        \"Answer: DISPUTED\\n\\n\"\n","\n","        \"Example 3:\\n\"\n","        \"Claim: \\\"Ocean and surface temperature measurements find the planet continues to accumulate heat.\\\"\\n\"\n","        \"Evidence: \\\"Greenhouse gases trap heat radiating from the Earth to space.\\\", \"\n","         \"\\\"Energy from the Sun heats this layer, and the surface below, causing expansion of the air.\\\"\\n\"\n","        \"Answer: NOT_ENOUGH_INFO\\n\\n\"\n","\n","         \"Now classify the following claim:\\n\"\n","        f\"Claim: {claim_text}\\n\"\n","        f\"Evidence: {' [SEP] '.join(evidences)}\\n\"\n","        \"Answer: \"\n","    )\n","\n","    # Tokenize and generate output\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_len).input_ids.to(\"cuda\")\n","    output_ids = model.generate(input_ids, max_length=10)\n","    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","    # Ensure the output is one of the valid labels\n","    valid_labels = [\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n","    output = output.strip().upper()\n","\n","    return output if output in valid_labels else \"NOT_ENOUGH_INFO\""]},{"cell_type":"markdown","metadata":{"id":"yG3uMT-8XHtG"},"source":["Few-shot Learning (Role Play Prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-05-17T09:05:02.765777Z","iopub.status.busy":"2025-05-17T09:05:02.765577Z","iopub.status.idle":"2025-05-17T09:05:02.780132Z","shell.execute_reply":"2025-05-17T09:05:02.779403Z","shell.execute_reply.started":"2025-05-17T09:05:02.765762Z"},"id":"Ngk3dilGRsWO","trusted":true},"outputs":[],"source":["def few_shot_roleplay_prompt_classification(claim_text, evidences, tokenizer, model, max_len=512):\n","\n","    prompt = (\n","         \"You are a fact-checking assistant and your task is to classify if the evidences SUPPORTS, REFUTES, have NOT_ENOUGH_INFO or DISPUTED regarding the claim. Examples are provided below for reference.\\n\"\n","\n","        \"Example 1:\\n\"\n","        \"Claim: \\\"Our harmless emissions of trifling quantities of carbon dioxide cannot possibly acidify the oceans.\\\"\\n\"\n","        \"Evidence: \\\"Carbon dioxide also causes ocean acidification because it dissolves in water to form carbonic acid.\\\", \"\n","        \"\\\"Marine calcifiers exhibit mixed responses to CO 2-induced ocean acidification.\\\"\\n\"\n","        \"Answer: REFUTES\\n\\n\"\n","\n","        \"Example 2:\\n\"\n","        \"Claim: \\\"Sea-level rise does not seem to depend on ocean temperature, and certainly not on CO2\\\"\\n\"\n","        \"Evidence: \\\"This depth depends on (among other things) temperature and the amount of CO 2 dissolved in the ocean.\\\", \"\n","        \"\\\"Because different climate models have slightly different patterns of ocean heating, they do not agree fully on the predictions for the contribution of ocean heating on sea level rise.\\\"\\n\"\n","        \"Answer: DISPUTED\\n\\n\"\n","\n","        \"Example 3:\\n\"\n","        \"Claim: \\\"Ocean and surface temperature measurements find the planet continues to accumulate heat.\\\"\\n\"\n","        \"Evidence: \\\"Greenhouse gases trap heat radiating from the Earth to space.\\\", \"\n","         \"\\\"Energy from the Sun heats this layer, and the surface below, causing expansion of the air.\\\"\\n\"\n","        \"Answer: NOT_ENOUGH_INFO\\n\\n\"\n","\n","         \"Now classify the following claim:\\n\"\n","        f\"Claim: {claim_text}\\n\"\n","        f\"Evidence: {' [SEP] '.join(evidences)}\\n\"\n","        \"Answer: \"\n","    )\n","\n","    # Tokenize and generate output\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_len).input_ids.to(\"cuda\")\n","    output_ids = model.generate(input_ids, max_length=10)\n","    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","    # Ensure the output is one of the valid labels\n","    valid_labels = [\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n","    output = output.strip().upper()\n","\n","    return output if output in valid_labels else \"NOT_ENOUGH_INFO\""]},{"cell_type":"markdown","metadata":{"id":"fU8ANaIJXn_C"},"source":["LLM Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-05-17T09:05:02.922776Z","iopub.status.busy":"2025-05-17T09:05:02.922378Z","iopub.status.idle":"2025-05-17T09:08:19.617713Z","shell.execute_reply":"2025-05-17T09:08:19.617090Z","shell.execute_reply.started":"2025-05-17T09:05:02.922759Z"},"id":"VQ55moobRY0Z","trusted":true},"outputs":[],"source":["# pip install accelerate\n","import time\n","import json\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","\n","def evaluate_llm(dev_data, mode, tokenizer, model ):\n","\n","    start_time = time.time()\n","\n","    # Define the label map to ensure consistency\n","    label_map = {'SUPPORTS': 0, 'REFUTES': 1, 'NOT_ENOUGH_INFO': 2, 'DISPUTED': 3}\n","\n","    # Initialize lists for storing ground truth and predictions\n","    ground_truths = []\n","    predictions = []\n","\n","    for item in dev_data:\n","        claim_id = item[\"claim_id\"]\n","        claim_text = item[\"claim_text\"]\n","        evidences = item[\"evidences\"]\n","        true_label = item[\"claim_label\"]\n","\n","        # zero-shot direct prompting\n","        if mode == \"zero-shot-direct\":\n","          predicted_label = zero_shot_direct_prompt_classification(claim_text, evidences, tokenizer, model )\n","\n","        # zero-shot role play prompting\n","        if mode == \"zero-shot-role-play\":\n","          predicted_label = zero_shot_roleplay_prompt_classification(claim_text, evidences, tokenizer, model )\n","\n","        # few-shot direct prompting\n","        if mode == \"few-shot-direct\":\n","          predicted_label = few_shot_direct_prompt_classification(claim_text, evidences, tokenizer, model )\n","\n","        # few-shot role play prompting\n","        if mode == \"few-shot-role-play\":\n","          predicted_label = few_shot_roleplay_prompt_classification(claim_text, evidences, tokenizer, model )\n","\n","        # Convert labels to integers using the label map\n","        ground_truths.append(label_map[true_label])\n","        predictions.append(label_map[predicted_label])\n","\n","    end_time = time.time()\n","    total_inference_time = end_time - start_time\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(ground_truths, predictions)\n","    precision = precision_score(ground_truths, predictions, average='weighted', zero_division=0)\n","    recall = recall_score(ground_truths, predictions, average='weighted', zero_division=0)\n","    f1 = f1_score(ground_truths, predictions, average='weighted', zero_division=0)\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(ground_truths, predictions)\n","    print(\"Confusion Matrix:\\n\", cm)\n","\n","    # Print metrics\n","    print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","\n","    # Return results and metrics\n","    return {\n","        \"inference_time\": total_inference_time,\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1\n","    }\n","\n","# Evaluate\n","with open('/kaggle/input/claim-evidence-pair/claim-evidence-set/claim-evidence-dev_set.json', 'r') as f:\n","  dev_data = json.load(f)\n","\n","prompting_mode = [\"zero-shot-direct\", \"zero-shot-role-play\", \"few-shot-direct\", \"few-shot-role-play\"]\n","\n","for mode in prompting_mode:\n","  print(f\"Prompting Mode: {mode}\")\n","  tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n","  model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n","  results = evaluate_llm(dev_data, mode, tokenizer, model )\n","  print(results)\n","  print(\"-----------------------------------------------------------\")"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":7381856,"sourceId":11758843,"sourceType":"datasetVersion"}],"dockerImageVersionId":31041,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":4}
